# Task 24: ìŒì„± STT API êµ¬í˜„ (FastAPI)

## âš ï¸ ìƒíƒœ: ì§„í–‰ ì¤‘ (Phase 1 ì™„ë£Œ)

## ğŸ“‹ ì‘ì—… ê°œìš”

Windows ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤(ë””ìŠ¤ì½”ë“œ, ë¸Œë¼ìš°ì € ë“±)ì—ì„œ ìº¡ì²˜í•œ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ ë°›ì•„:
1. **Whisper STT**ë¡œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
2. **KoELECTRA**ë¡œ ìœ í•´ì„± íŒë³„ (0: ì •ìƒ, 1: ìœ í•´)
3. **ê²°ê³¼ë¥¼ í´ë¼ì´ì–¸íŠ¸ì— ì‹¤ì‹œê°„ ë°˜í™˜** (WebSocket)

## ğŸ¯ í•µì‹¬ ëª©í‘œ

- **ì§€ì—°ìœ¨ 3ì´ˆ ì´ë‚´** ë‹¬ì„± (ê³„íšì„œ ìš”êµ¬ì‚¬í•­)
- WebSocketì„ í†µí•œ ì‹¤ì‹œê°„ ì–‘ë°©í–¥ í†µì‹  êµ¬í˜„
- ì˜¤ë””ì˜¤ ì²­í¬ ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (ë²„í¼ ê´€ë¦¬)

## ğŸ“¦ í•„ìˆ˜ ì˜ì¡´ì„±

```bash
# server/requirements.txtì— ì¶”ê°€
fastapi==0.104.1
uvicorn[standard]==0.24.0
websockets==12.0
numpy==2.1.2  # Python 3.13 í˜¸í™˜ ê°€ëŠ¥í•œ ìµœì‹  ë²„ì „ ì‚¬ìš©
pydub==0.25.1  # ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ìš©
# ì•„ë˜ íŒ¨í‚¤ì§€ëŠ” Python 3.12 ë¯¸ë§Œ í™˜ê²½ì—ì„œ ìë™ ì„¤ì¹˜
openai-whisper==20231117
torch==2.1.0
torchaudio==2.1.0
transformers==4.35.0
```

> â„¹ï¸ **ì£¼ì˜**: í˜„ì¬ ê°œë°œ í™˜ê²½(Py 3.13)ì—ì„œëŠ” Whisper/Torch/Transformersì˜ ê³µì‹ íœ ì´ ì œê³µë˜ì§€ ì•Šì•„
> `python_version < "3.12"` ì¡°ê±´ìœ¼ë¡œ ì„¤ì¹˜ë¥¼ ê±´ë„ˆë›°ë„ë¡ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.  
> ì‹¤ì œ ë°°í¬ í™˜ê²½ì—ì„œëŠ” Python 3.11 ê¸°ë°˜ venvë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜, ìˆ˜ë™ìœ¼ë¡œ í˜¸í™˜ ë²„ì „ì„ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.

## ğŸ“ ì‘ì—… ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1: WebSocket ì—”ë“œí¬ì¸íŠ¸ êµ¬ì¶• (í…ŒìŠ¤íŠ¸ ê°€ëŠ¥)

- [x] **1.1. WebSocket ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€**
  ```python
  # server/main.py
  from fastapi import FastAPI, WebSocket, WebSocketDisconnect
  
  @app.websocket("/ws/audio")
  async def audio_stream(websocket: WebSocket):
      await websocket.accept()
      try:
          while True:
              # ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹  (ë°”ì´ë„ˆë¦¬)
              audio_data = await websocket.receive_bytes()
              # TODO: ì²˜ë¦¬ ë¡œì§
              await websocket.send_json({"status": "received", "size": len(audio_data)})
      except WebSocketDisconnect:
          print("Client disconnected")
  ```
  
  **ì§„í–‰ í˜„í™© (2025-11-11)**:
  - `/ws/audio` WebSocket ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„ ì™„ë£Œ
  - ì—°ê²° ì§í›„ `"Connected"` í…ìŠ¤íŠ¸ ì „ì†¡ ë° ë°”ì´ë„ˆë¦¬/í…ìŠ¤íŠ¸ ì…ë ¥ ë¶„ê¸° ì²˜ë¦¬
  - ë°”ì´ë„ˆë¦¬ ìˆ˜ì‹  ì‹œ `{"status": "received", "size": ...}` JSON ì‘ë‹µ ë°˜í™˜
  - ì˜ˆì™¸ ì²˜ë¦¬(`WebSocketDisconnect`, ê·¸ ì™¸ ì˜¤ë¥˜`)ì™€ ì„œë²„ ë¡œê·¸ ë©”ì‹œì§€ ì¶”ê°€

  **ê²€ì¦ ë°©ë²•**:
  - ë‹¨ìœ„ í…ŒìŠ¤íŠ¸: `server/tests/test_ws_audio.py`
    ```bash
    cd server
    venv\Scripts\python.exe -m pytest tests/test_ws_audio.py
    # âœ… 1 passed
    ```
  - ìˆ˜ë™ í…ŒìŠ¤íŠ¸: `wscat -c ws://localhost:8000/ws/audio -b`
  
  **í…ŒìŠ¤íŠ¸ ë°©ë²•**:
  ```bash
  # í„°ë¯¸ë„ 1: ì„œë²„ ì‹¤í–‰
  cd server
  uvicorn main:app --reload
  
  # í„°ë¯¸ë„ 2: wscatìœ¼ë¡œ í…ŒìŠ¤íŠ¸
  npm install -g wscat
  wscat -c ws://localhost:8000/ws/audio -b
  # ë°”ì´ë„ˆë¦¬ ë°ì´í„° ì „ì†¡ í…ŒìŠ¤íŠ¸
  ```

- [x] **1.2. ì˜¤ë””ì˜¤ ë²„í¼ ê´€ë¦¬ í´ë˜ìŠ¤ êµ¬í˜„**
  ```python
  # server/audio/buffer_manager.py
  import numpy as np
  from collections import deque
  
  class AudioBufferManager:
      def __init__(self, sample_rate=16000, chunk_duration_sec=1.0):
          self.sample_rate = sample_rate
          self.chunk_size = int(sample_rate * chunk_duration_sec)
          self.buffer = deque()
      
      def add_chunk(self, audio_bytes: bytes):
          # bytes â†’ numpy array ë³€í™˜
          audio_np = np.frombuffer(audio_bytes, dtype=np.int16)
          self.buffer.extend(audio_np)
      
      def get_processed_chunk(self) -> np.ndarray:
          if len(self.buffer) >= self.chunk_size:
              chunk = np.array([self.buffer.popleft() for _ in range(self.chunk_size)])
              # ì •ê·œí™” (-1.0 ~ 1.0)
              return chunk.astype(np.float32) / 32768.0
          return None
  ```
  
  **ì§„í–‰ í˜„í™© (2025-11-11)**:
  - `server/audio/buffer_manager.py` ìƒì„± ë° `AudioBufferManager` êµ¬í˜„
  - 1ì´ˆ(í˜¹ì€ ì„¤ì •ëœ ê¸¸ì´) ë‹¨ìœ„ ì²­í¬ ì •ê·œí™”(float32) ë°˜í™˜ ê¸°ëŠ¥ ì™„ë£Œ
  - ì…ë ¥ ê²€ì¦(ìƒ˜í”Œë ˆì´íŠ¸/ì²­í¬ ê¸¸ì´)ê³¼ ë²„í¼ ì´ˆê¸°í™” ë©”ì„œë“œ ì œê³µ

  **ê²€ì¦ ë°©ë²•**:
  - ë‹¨ìœ„ í…ŒìŠ¤íŠ¸: `server/tests/test_audio_buffer_manager.py`
    ```bash
    cd server
    venv\Scripts\python.exe -m pytest tests/test_audio_buffer_manager.py
    # âœ… 4 passed
    ```

- [x] **2.1. Whisper ëª¨ë¸ ë¡œë” êµ¬í˜„**
  ```python
  # server/audio/whisper_service.py
  from audio.whisper_service import WhisperSTTService
  
  service = WhisperSTTService(model_name="base")
  text = service.transcribe(audio_chunk_np)
  ```
  
  **ì§„í–‰ í˜„í™© (2025-11-11)**:
  - `WhisperSTTService` í´ë˜ìŠ¤ êµ¬í˜„ (`model_loader` ì£¼ì… ì§€ì›, ì…ë ¥ ê²€ì¦ í¬í•¨)
  - Whisper ë¯¸ì„¤ì¹˜ ì‹œ ì‚¬ìš©ì ì¹œí™”ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€ ì œê³µ
  - CPU í™˜ê²½ ê¸°ë³¸ê°’(`fp16=False`) ì„¤ì • ë° ë¡œê¹… ì¶”ê°€
  
  **ê²€ì¦ ë°©ë²•**:
  - ë‹¨ìœ„ í…ŒìŠ¤íŠ¸: `server/tests/test_whisper_service.py`  
    (ê°€ì§œ Whisper ëª¨ë“ˆì„ ì£¼ì…í•˜ì—¬ ë¹ ë¥´ê²Œ ê²€ì¦)
    ```bash
    cd server
    venv\Scripts\python.exe -m pytest tests/test_whisper_service.py
    # âœ… 3 passed
    ```

- [ ] **2.2. ì‹¤ì œ ì˜¤ë””ì˜¤ íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸**
  ```bash
  # í•œêµ­ì–´ ìŒì„± ìƒ˜í”Œ ë‹¤ìš´ë¡œë“œ (ì˜ˆ: YouTube ë˜ëŠ” ë…¹ìŒ)
  # test_audio.wav íŒŒì¼ì„ server/ ë””ë ‰í† ë¦¬ì— ì¤€ë¹„
  
  # test_whisper_real.py
  import whisper
  import numpy as np
  from pydub import AudioSegment
  
  audio = AudioSegment.from_file("test_audio.wav")
  audio = audio.set_frame_rate(16000).set_channels(1)
  audio_np = np.array(audio.get_array_of_samples(), dtype=np.float32) / 32768.0
  
  model = whisper.load_model("base")
  result = model.transcribe(audio_np, language="ko")
  print(f"âœ… Transcribed: {result['text']}")
  ```

### Phase 3: KoELECTRA ìœ í•´ì„± íŒë³„ í†µí•©

- [ ] **3.1. KoELECTRA ë¶„ë¥˜ê¸° êµ¬í˜„**
  ```python
  # server/nlp/harmful_classifier.py
  from transformers import AutoTokenizer, AutoModelForSequenceClassification
  import torch
  
  class HarmfulTextClassifier:
      def __init__(self, model_name="monologg/koelectra-base-v3-discriminator"):
          print(f"Loading KoELECTRA model: {model_name}...")
          self.tokenizer = AutoTokenizer.from_pretrained(model_name)
          self.model = AutoModelForSequenceClassification.from_pretrained(
              model_name,
              num_labels=2  # 0: ì •ìƒ, 1: ìœ í•´
          )
          # TODO: Fine-tuned ëª¨ë¸ë¡œ êµì²´ (íŒ€ì› ì†ì°¬ìš°, ì‹ ë™ì„)
          print("âœ… KoELECTRA model loaded!")
      
      def predict(self, text: str) -> dict:
          """
          Returns:
              {
                  "is_harmful": bool (0 or 1),
                  "confidence": float (0.0 ~ 1.0),
                  "text": str
              }
          """
          if not text.strip():
              return {"is_harmful": False, "confidence": 0.0, "text": ""}
          
          inputs = self.tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
          with torch.no_grad():
              outputs = self.model(**inputs)
              probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
              predicted_class = torch.argmax(probs, dim=-1).item()
              confidence = probs[0][predicted_class].item()
          
          return {
              "is_harmful": bool(predicted_class),
              "confidence": confidence,
              "text": text
          }
  ```
  
  **í…ŒìŠ¤íŠ¸ ë°©ë²•**:
  ```python
  # server/test_classifier.py
  from nlp.harmful_classifier import HarmfulTextClassifier
  
  classifier = HarmfulTextClassifier()
  
  # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
  test_cases = [
      "ì•ˆë…•í•˜ì„¸ìš”, ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!",
      "ìš•ì„¤ í…ŒìŠ¤íŠ¸ ë¬¸ì¥",  # ì‹¤ì œ ìš•ì„¤ë¡œ êµì²´
      "ë„ˆ ì •ë§ ë°”ë³´ ê°™ì•„",
  ]
  
  for text in test_cases:
      result = classifier.predict(text)
      print(f"Text: {text}")
      print(f"Result: {result}")
      print("-" * 50)
  
  print("âœ… Classifier test passed!")
  ```

### Phase 4: ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•© (WebSocket)

- [ ] **4.1. ì „ì²´ íŒŒì´í”„ë¼ì¸ êµ¬í˜„**
  ```python
  # server/main.py (ì—…ë°ì´íŠ¸)
  from audio.buffer_manager import AudioBufferManager
  from audio.whisper_service import WhisperSTTService
  from nlp.harmful_classifier import HarmfulTextClassifier
  
  # ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (ì•± ì‹œì‘ ì‹œ ì´ˆê¸°í™”)
  stt_service = WhisperSTTService(model_name="base")
  classifier = HarmfulTextClassifier()
  
  @app.websocket("/ws/audio")
  async def audio_stream(websocket: WebSocket):
      await websocket.accept()
      buffer_manager = AudioBufferManager(sample_rate=16000, chunk_duration_sec=1.0)
      
      try:
          while True:
              # 1. ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹ 
              audio_bytes = await websocket.receive_bytes()
              buffer_manager.add_chunk(audio_bytes)
              
              # 2. ë²„í¼ê°€ ì¶©ë¶„íˆ ìŒ“ì´ë©´ ì²˜ë¦¬
              audio_chunk = buffer_manager.get_processed_chunk()
              if audio_chunk is not None:
                  # 3. STT ë³€í™˜
                  text = stt_service.transcribe(audio_chunk)
                  
                  # 4. ìœ í•´ì„± íŒë³„
                  result = classifier.predict(text)
                  
                  # 5. ê²°ê³¼ ì „ì†¡
                  await websocket.send_json({
                      "text": text,
                      "is_harmful": result["is_harmful"],
                      "confidence": result["confidence"],
                      "timestamp": time.time()
                  })
      
      except WebSocketDisconnect:
          print("Client disconnected")
      except Exception as e:
          print(f"Error in audio_stream: {e}")
          await websocket.close(code=1011, reason=str(e))
  ```

- [ ] **4.2. ì„±ëŠ¥ ìµœì í™” ê²€í† **
  - [ ] Whisper ëª¨ë¸ í¬ê¸° ì¡°ì • (tiny, base, small ì¤‘ ì„ íƒ)
  - [ ] GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ ë° ì„¤ì •
  - [ ] ë¹„ë™ê¸° ì²˜ë¦¬ (ThreadPoolExecutor) ê³ ë ¤
  
  ```python
  # GPU ì„¤ì • ì˜ˆì‹œ
  import torch
  device = "cuda" if torch.cuda.is_available() else "cpu"
  self.model.to(device)
  ```

### Phase 5: í†µí•© í…ŒìŠ¤íŠ¸ ë° ì§€ì—°ìœ¨ ì¸¡ì •

- [ ] **5.1. End-to-End í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸**
  ```python
  # server/test_e2e.py
  import asyncio
  import websockets
  import numpy as np
  import time
  
  async def test_audio_pipeline():
      uri = "ws://localhost:8000/ws/audio"
      async with websockets.connect(uri) as websocket:
          print("âœ… WebSocket connected")
          
          # ë”ë¯¸ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ìƒì„± (16kHz, 1ì´ˆì”© ì „ì†¡)
          for i in range(5):
              # 1ì´ˆ ë¶„ëŸ‰ ì˜¤ë””ì˜¤ ìƒì„±
              audio_chunk = (np.random.randn(16000) * 0.1).astype(np.float32)
              audio_bytes = (audio_chunk * 32768).astype(np.int16).tobytes()
              
              start_time = time.time()
              await websocket.send(audio_bytes)
              
              # ì‘ë‹µ ëŒ€ê¸°
              response = await websocket.recv()
              latency = time.time() - start_time
              
              print(f"Chunk {i+1}: {response}")
              print(f"Latency: {latency:.2f}s")
              
              if latency > 3.0:
                  print("âš ï¸ WARNING: Latency exceeds 3 seconds!")
          
          print("âœ… E2E test completed!")
  
  asyncio.run(test_audio_pipeline())
  ```

- [ ] **5.2. ì§€ì—°ìœ¨ 3ì´ˆ ì´ë‚´ ë‹¬ì„± í™•ì¸**
  - ê° ë‹¨ê³„ë³„ ì‹œê°„ ì¸¡ì • (STT, ë¶„ë¥˜)
  - ë³‘ëª© ì§€ì  íŒŒì•… ë° ìµœì í™”

## ğŸ”— ê´€ë ¨ íŒŒì¼

### ìƒì„±í•  íŒŒì¼
- `server/audio/buffer_manager.py` - ì˜¤ë””ì˜¤ ë²„í¼ ê´€ë¦¬
- `server/audio/whisper_service.py` - Whisper STT ì„œë¹„ìŠ¤
- `server/nlp/harmful_classifier.py` - KoELECTRA ìœ í•´ì„± ë¶„ë¥˜ê¸°
- `server/main.py` - WebSocket ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
- `server/tests/test_ws_audio.py` - WebSocket ì—”ë“œí¬ì¸íŠ¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
- `server/tests/test_whisper_service.py` - Whisper ì„œë¹„ìŠ¤ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

### ìˆ˜ì •í•  íŒŒì¼
- `server/requirements.txt` - ì˜ì¡´ì„± ì¶”ê°€ (`pytest`, `httpx`, `numpy`, `pydub`, Whisper ê³„ì—´ ì¡°ê±´ë¶€ ì„¤ì¹˜)
- `server/README.md` - API ë¬¸ì„œ ì—…ë°ì´íŠ¸

## ğŸ“Š í…ŒìŠ¤íŠ¸ ê³„íš

| ë‹¨ê³„ | í…ŒìŠ¤íŠ¸ í•­ëª© | ì„±ê³µ ê¸°ì¤€ | ìš°ì„ ìˆœìœ„ |
|------|-------------|-----------|----------|
| 1 | WebSocket ì—°ê²° | wscatìœ¼ë¡œ ì—°ê²° ì„±ê³µ | High |
| 2 | ë²„í¼ ê´€ë¦¬ | ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ í™•ì¸ | High |
| 3 | Whisper STT | í•œêµ­ì–´ ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜ | High |
| 4 | KoELECTRA ë¶„ë¥˜ | ìœ í•´ì„± íŒë³„ ì •í™•ë„ | High |
| 5 | ì „ì²´ íŒŒì´í”„ë¼ì¸ | E2E ì§€ì—°ìœ¨ 3ì´ˆ ì´ë‚´ | Critical |

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ëª¨ë¸ í¬ê¸°ì™€ ì„±ëŠ¥ íŠ¸ë ˆì´ë“œì˜¤í”„**
   - Whisper-tiny: ë¹ ë¦„, ì •í™•ë„ ë‚®ìŒ
   - Whisper-base: ì¤‘ê°„ (ê¶Œì¥)
   - Whisper-small: ëŠë¦¼, ì •í™•ë„ ë†’ìŒ

2. **GPU ê°€ìš©ì„±**
   - CPUë§Œ ì‚¬ìš© ì‹œ ì§€ì—°ìœ¨ ì¦ê°€ ê°€ëŠ¥
   - GPU ì‚¬ìš© ì‹œ `torch.cuda.is_available()` í™•ì¸

3. **ì˜¤ë””ì˜¤ í¬ë§·**
   - í´ë¼ì´ì–¸íŠ¸ì—ì„œ 16kHz, mono, PCM 16-bitë¡œ ì „ì†¡
   - ë‹¤ë¥¸ í¬ë§· ìˆ˜ì‹  ì‹œ ë¦¬ìƒ˜í”Œë§ í•„ìš”

4. **ì—ëŸ¬ ì²˜ë¦¬**
   - WebSocket ì—°ê²° ëŠê¹€ ì‹œ ë²„í¼ ì •ë¦¬
   - STT/ë¶„ë¥˜ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì‘ë‹µ ì „ì†¡

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- [Whisper GitHub](https://github.com/openai/whisper)
- [FastAPI WebSockets](https://fastapi.tiangolo.com/advanced/websockets/)
- [KoELECTRA Hugging Face](https://huggingface.co/monologg/koelectra-base-v3-discriminator)

## ğŸ—’ï¸ ì—…ë°ì´íŠ¸ ë¡œê·¸

- 2025-11-11: Phase 1 `/ws/audio` ì—”ë“œí¬ì¸íŠ¸ ë° ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ êµ¬ì¶•, ë¬¸ì„œ ê°±ì‹ 
- 2025-11-11: `AudioBufferManager` êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸ ì¶”ê°€, `numpy==2.1.2`ë¡œ ìš”êµ¬ì‚¬í•­ ì—…ë°ì´íŠ¸
- 2025-11-11: `WhisperSTTService` êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸ ì‘ì„±, Whisper/Torch ì¡°ê±´ë¶€ ì˜ì¡´ì„± ì¶”ê°€

## ğŸ”„ ë‹¤ìŒ ì‘ì—…

ì´ ì‘ì—… ì™„ë£Œ í›„:
- **T25: ìŒì„± Electron ì—°ë™** ì‹œì‘
  - Windows ì˜¤ë””ì˜¤ ìº¡ì²˜
  - WebSocket í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„
  - ë³¼ë¥¨ ì¡°ì ˆ/ë¹„í”„ìŒ ì²˜ë¦¬

---

**ì‘ì—… ì‹œì‘ ëª…ë ¹ì–´ (Cursor Agentì—ê²Œ ì œê³µ)**:

```
ì‘ì—…: T24 - ìŒì„± STT API êµ¬í˜„ (FastAPI)

1. **ë§ˆìŠ¤í„° í”Œëœ í™•ì¸**
   - @PROJECT_SPEC.mdì—ì„œ T24 ìš”êµ¬ì‚¬í•­ í™•ì¸
   - @AISPNLP_ì¢…í•©_í”„ë¡œì íŠ¸_ê³„íšì„œ.pdfì˜ "ìŒì„± í•„í„° íë¦„ë„" ì°¸ì¡°

2. **ì´ ë¬¸ì„œ ì°¸ì¡°**
   - @docs/24-audio-stt-api.mdì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì§„í–‰

3. **ì‘ì—… ì§€ì‹œ**
   - Phase 1ë¶€í„° ì‹œì‘: WebSocket ì—”ë“œí¬ì¸íŠ¸ êµ¬ì¶•
   - ê° Phase ì™„ë£Œ í›„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
   - í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸ í›„ ë‹¤ìŒ Phase ì§„í–‰
```
