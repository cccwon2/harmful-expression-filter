# Task 27: Deepgram STT ì„œë²„ ì—°ë™ (Whisper â†’ Deepgram ë§ˆì´ê·¸ë ˆì´ì…˜)

## âš ï¸ ìƒíƒœ: ì§„í–‰ ì¤‘

## âš ï¸ ì¤‘ìš”: Python í™˜ê²½ ì„¤ì •

**Whisper í˜¸í™˜ì„± ë¬¸ì œë¡œ ì¸í•´ `server/venv311` (Python 3.11) í™˜ê²½ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.**

```bash
# ì„œë²„ ì‹¤í–‰ ì‹œ venv311 í™œì„±í™” í•„ìˆ˜
cd server
venv311\Scripts\activate  # Windows
# source venv311/bin/activate  # Linux/Mac
uvicorn main:app --reload
```

## ğŸ“‹ ì‘ì—… ê°œìš”

T24ì—ì„œ êµ¬í˜„í•œ Whisper ê¸°ë°˜ STTë¥¼ **Deepgram ìƒìš© API**ë¡œ êµì²´í•˜ì—¬:
1. **ë ˆì´í„´ì‹œ ë‹¨ì¶•** (ëª©í‘œ: 2ì´ˆ ì´ë‚´)
2. **STT ì •í™•ë„ í–¥ìƒ** (í•œêµ­ì–´ íŠ¹í™”)
3. **ì„œë²„ ë¶€í•˜ ê°ì†Œ** (GPU ë¶ˆí•„ìš”)

Deepgramì€ WebSocket ê¸°ë°˜ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì„ ì§€ì›í•˜ë©°, Whisper ëŒ€ë¹„ 2~3ë°° ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ í•µì‹¬ ëª©í‘œ

- âœ… **ë ˆì´í„´ì‹œ 2ì´ˆ ì´ë‚´** ë‹¬ì„± (Whisper ëŒ€ë¹„ 30~50% ë‹¨ì¶•)
- âœ… **í•œêµ­ì–´ ì •í™•ë„ í–¥ìƒ** (Deepgramì˜ í•œêµ­ì–´ ëª¨ë¸ í™œìš©)
- âœ… **ê¸°ì¡´ êµ¬ì¡° ìœ ì§€** (AudioProcessingPipeline ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜)
- âœ… **ë³´ì•ˆ ê°•í™”** (API í‚¤ëŠ” ì„œë²„ì—ì„œë§Œ ê´€ë¦¬)

## ğŸ“¦ í•„ìˆ˜ ì˜ì¡´ì„±
```bash
# server/requirements.txtì— ì¶”ê°€
deepgram-sdk>=5.3.0  # Deepgram Python SDK v5
websockets==12.0     # ì´ë¯¸ ìˆìŒ (T24)
```

## ğŸ”„ Whisper vs Deepgram ë¹„êµ

| í•­ëª© | Whisper (í˜„ì¬) | Deepgram (ëª©í‘œ) |
|------|---------------|----------------|
| ë ˆì´í„´ì‹œ (ì›œì—… í›„) | 1.99ì´ˆ | **1.0~1.5ì´ˆ** |
| ì´ˆê¸° ë¡œë”© ì‹œê°„ | 12ì´ˆ (GPU ì—†ìŒ) | **ì¦‰ì‹œ** (API í˜¸ì¶œ) |
| GPU ìš”êµ¬ì‚¬í•­ | í•„ìˆ˜ (ì„±ëŠ¥ìš©) | **ë¶ˆí•„ìš”** |
| í•œêµ­ì–´ ì§€ì› | ë²”ìš© | **ì–¸ì–´ íŠ¹í™” ëª¨ë¸** |
| ë¹„ìš© | ë¬´ë£Œ | ì¢…ëŸ‰ì œ (ë¶„ë‹¹ $0.0125) |
| ìŠ¤íŠ¸ë¦¬ë° | ë¶€ë¶„ ì§€ì› | **ì™„ë²½ ì§€ì›** |

## ğŸ“ ì‘ì—… ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1: DeepgramSTTService êµ¬í˜„

- [x] **1.1. Deepgram SDK ì„¤ì¹˜ ë° í…ŒìŠ¤íŠ¸**
```bash
  # âš ï¸ Whisper í˜¸í™˜ì„±ì„ ìœ„í•´ venv311 ì‚¬ìš© í•„ìš”
  cd server
  venv311\Scripts\activate  # Windows
  # source venv311/bin/activate  # Linux/Mac
  
  pip install --upgrade deepgram-sdk>=5.3.0
  
  # .env íŒŒì¼ì— API í‚¤ ì¶”ê°€
  echo "DEEPGRAM_API_KEY=your_api_key_here" >> .env
```
  
  **API í‚¤ ë°œê¸‰**: https://console.deepgram.com/signup
  - ë¬´ë£Œ í¬ë ˆë”§: $200 (ì•½ 16,000ë¶„)
  - í•œêµ­ì–´ ëª¨ë¸: `ko` ì–¸ì–´ ì½”ë“œ ì§€ì›

- [x] **1.2. DeepgramSTTService êµ¬í˜„ (SDK v5)**

```python
# [Server: server/audio/deepgram_service.py]
from deepgram import AsyncDeepgramClient
import asyncio
import os
import numpy as np
import logging

logger = logging.getLogger(__name__)

class DeepgramSTTService:
    """
    Deepgram WebSocket ê¸°ë°˜ ì‹¤ì‹œê°„ STT ì„œë¹„ìŠ¤ (SDK v5)
    WhisperSTTServiceì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€
    """
    
    def __init__(self, api_key: str = None, language: str = "ko", model: str = "nova-2"):
        self.api_key = api_key or os.getenv("DEEPGRAM_API_KEY")
        if not self.api_key:
            raise ValueError("DEEPGRAM_API_KEY not found in environment")
        
        self.language = language
        self.model = model
        
        try:
            self.deepgram = AsyncDeepgramClient(api_key=self.api_key)
            logger.info("âœ… DeepgramSTTService initialized (language: %s, model: %s)", language, model)
        except Exception as exc:
            raise DeepgramNotAvailableError(f"Deepgram ì´ˆê¸°í™” ì‹¤íŒ¨: {exc}") from exc
    
    async def transcribe_stream(self, audio_np: np.ndarray) -> str:
        """
        ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ Deepgramìœ¼ë¡œ ì „ì†¡í•˜ì—¬ í…ìŠ¤íŠ¸ ë³€í™˜ (SDK v5)
        
        Args:
            audio_np: float32 numpy array, normalized to [-1.0, 1.0]
        
        Returns:
            str: ë³€í™˜ëœ í…ìŠ¤íŠ¸ (ë¹ˆ ë¬¸ìì—´ ê°€ëŠ¥)
        """
        import time
        start_time = time.time()
        
        try:
            # ì…ë ¥ ê²€ì¦
            audio = np.asarray(audio_np, dtype=np.float32)
            audio_mean = float(np.mean(np.abs(audio)))
            
            # ì¡°ìš©í•œ ì˜¤ë””ì˜¤ ì¡°ê¸° ì¢…ë£Œ
            if audio_mean < 0.001:
                logger.info("Audio too quiet, skipping API call")
                return ""
            
            # float32 â†’ int16 ë³€í™˜
            audio_int16 = (audio * 32768).astype(np.int16)
            audio_bytes = audio_int16.tobytes()
            
            # SDK v5 API í˜¸ì¶œ (ì˜¬ë°”ë¥¸ ê²½ë¡œ: listen.v1.media.transcribe_file)
            # ëª¨ë“  ì¸ìëŠ” keyword-onlyì´ë¯€ë¡œ request=ë¡œ ëª…ì‹œí•´ì•¼ í•¨
            # raw audio bytesë¥¼ ì „ë‹¬í•  ë•ŒëŠ” encodingì„ ëª…ì‹œí•´ì•¼ í•¨ (sample_rateëŠ” íŒŒë¼ë¯¸í„°ë¡œ ì§€ì›ë˜ì§€ ì•ŠìŒ)
            response = await self.deepgram.listen.v1.media.transcribe_file(
                request=audio_bytes,  # bytesë¥¼ ì§ì ‘ ì „ë‹¬
                model=self.model,
                language=self.language,
                encoding="linear16",  # raw audio í˜•ì‹ ëª…ì‹œ (16kHz, 16-bit, monoëŠ” ê¸°ë³¸ê°’)
                smart_format=False,
                punctuate=False,
            )
            
            # ì‘ë‹µ íŒŒì‹±
            transcript = ""
            if response and response.results:
                channels = response.results.channels
                if channels and len(channels) > 0:
                    alternatives = channels[0].alternatives
                    if alternatives and len(alternatives) > 0:
                        transcript = alternatives[0].transcript.strip()
            
            # ë ˆì´í„´ì‹œ ë¡œê¹…
            elapsed_ms = (time.time() - start_time) * 1000
            logger.info("Deepgram: %.2fms | '%s'", elapsed_ms, transcript[:50])
            
            if elapsed_ms > 2000:
                logger.warning("Latency exceeds 2s: %.2fms", elapsed_ms)
            
            return transcript
        
        except Exception as exc:
            logger.exception("Deepgram transcription error")
            return ""
    
    def transcribe(self, audio_np: np.ndarray) -> str:
        """ë™ê¸° ë²„ì „ (WhisperSTTService í˜¸í™˜)"""
        return asyncio.run(self.transcribe_stream(audio_np))
```

- [ ] **1.3. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸**
```python
  # server/tests/test_deepgram_service.py
  import pytest
  import numpy as np
  from audio.deepgram_service import DeepgramSTTService
  
  @pytest.fixture
  def deepgram_service():
      """DeepgramSTTService ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì‹¤ì œ API í˜¸ì¶œ)"""
      return DeepgramSTTService()
  
  @pytest.mark.asyncio
  async def test_transcribe_stream_success(deepgram_service):
      """ì •ìƒ ì˜¤ë””ì˜¤ ì²­í¬ ì „ì†¡ í…ŒìŠ¤íŠ¸"""
      # 1ì´ˆì§œë¦¬ ë”ë¯¸ ì˜¤ë””ì˜¤ (ë¬´ìŒ)
      audio_chunk = np.zeros(16000, dtype=np.float32)
      
      result = await deepgram_service.transcribe_stream(audio_chunk)
      
      # ë¬´ìŒì´ë¯€ë¡œ ë¹ˆ ë¬¸ìì—´ì´ ë°˜í™˜ë˜ì–´ì•¼ í•¨
      assert isinstance(result, str)
      assert result == ""
  
  @pytest.mark.asyncio
  async def test_transcribe_stream_with_real_audio(deepgram_service):
      """ì‹¤ì œ ì˜¤ë””ì˜¤ íŒŒì¼ í…ŒìŠ¤íŠ¸ (tests/data/sample_ko.wav í•„ìš”)"""
      import wave
      
      with wave.open("tests/data/sample_ko.wav", "rb") as wf:
          audio_bytes = wf.readframes(wf.getnframes())
          audio_np = np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32) / 32768.0
      
      result = await deepgram_service.transcribe_stream(audio_np[:16000])
      
      # ê²°ê³¼ê°€ ë¹„ì–´ìˆì§€ ì•Šì•„ì•¼ í•¨
      assert isinstance(result, str)
      assert len(result) > 0
      print(f"âœ… Transcription result: {result}")
  
  def test_transcribe_sync(deepgram_service):
      """ë™ê¸° ë²„ì „ í…ŒìŠ¤íŠ¸ (WhisperSTTService í˜¸í™˜ì„±)"""
      audio_chunk = np.zeros(16000, dtype=np.float32)
      result = deepgram_service.transcribe(audio_chunk)
      assert isinstance(result, str)
```
  
  **ì‹¤í–‰**:
```bash
  cd server
  pytest tests/test_deepgram_service.py -v
  
  # ì‹¤ì œ ì˜¤ë””ì˜¤ í…ŒìŠ¤íŠ¸ (sample_ko.wav ìˆì„ ë•Œë§Œ)
  pytest tests/test_deepgram_service.py::test_transcribe_stream_with_real_audio -v
```

### Phase 2: AudioProcessingPipeline í†µí•©

- [ ] **2.1. AudioProcessingPipeline ìˆ˜ì •**
```python
  # server/audio/pipeline.py (ìˆ˜ì •)
  from audio.whisper_service import WhisperSTTService
  from audio.deepgram_service import DeepgramSTTService  # âœ… ì¶”ê°€
  from nlp.harmful_classifier import HarmfulTextClassifier
  
  class AudioProcessingPipeline:
      def __init__(
          self,
          stt_service,  # WhisperSTTService ë˜ëŠ” DeepgramSTTService
          classifier: HarmfulTextClassifier,
          sample_rate: int = 16_000,
          chunk_duration_sec: float = 1.0,
      ):
          self.stt_service = stt_service
          self.classifier = classifier
          self.buffer_manager = AudioBufferManager(sample_rate, chunk_duration_sec)
      
      # ... ë‚˜ë¨¸ì§€ ì½”ë“œ ë™ì¼ (ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜) ...
```

- [ ] **2.2. main.pyì—ì„œ Deepgram ì‚¬ìš©**
```python
  # server/main.py (ìˆ˜ì •)
  from audio.deepgram_service import DeepgramSTTService  # âœ… ë³€ê²½
  from audio.pipeline import AudioProcessingPipeline
  from nlp.harmful_classifier import HarmfulTextClassifier
  
  # ì „ì—­ ë³€ìˆ˜
  stt_service = None
  classifier = None
  pipeline = None
  
  @app.on_event("startup")
  async def startup_event():
      global stt_service, classifier, pipeline
      
      try:
          # âœ… Deepgram ì‚¬ìš© (Whisper ëŒ€ì‹ )
          stt_service = DeepgramSTTService(language="ko")
          print("âœ… Deepgram STT service initialized")
          
          classifier = HarmfulTextClassifier()
          print("âœ… Harmful text classifier initialized")
          
          pipeline = AudioProcessingPipeline(
              stt_service=stt_service,
              classifier=classifier,
              sample_rate=16_000,
              chunk_duration_sec=1.0,
          )
          print("âœ… Audio processing pipeline initialized")
      
      except Exception as e:
          print(f"âŒ Failed to initialize services: {e}")
  
  @app.websocket("/ws/audio")
  async def audio_stream(websocket: WebSocket):
      await websocket.accept()
      await websocket.send_text("Connected (Deepgram STT)")  # âœ… ë³€ê²½
      
      try:
          while True:
              data = await websocket.receive()
              
              if "bytes" in data:
                  audio_bytes = data["bytes"]
                  
                  # íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬
                  result = await pipeline.process_audio(audio_bytes)
                  
                  if result:
                      await websocket.send_json({
                          "text": result.text,
                          "is_harmful": result.is_harmful,
                          "confidence": result.confidence,
                          "timestamp": result.timestamp,
                          "processing_time_ms": result.processing_time_ms,
                          "chunk_duration_sec": result.chunk_duration_sec,
                      })
      
      except WebSocketDisconnect:
          print("Client disconnected")
      except Exception as e:
          print(f"Error in audio stream: {e}")
```

### Phase 3: E2E í…ŒìŠ¤íŠ¸ ë° ë ˆì´í„´ì‹œ ë¹„êµ

- [ ] **3.1. E2E í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (Deepgram ë²„ì „)**
```python
  # server/tests/test_e2e_deepgram.py
  import asyncio
  import numpy as np
  import websockets
  import time
  
  async def main():
      uri = "ws://127.0.0.1:8000/ws/audio"
      
      print("ğŸ§ª Deepgram E2E Test")
      print("=" * 50)
      
      async with websockets.connect(uri) as websocket:
          # ì—°ê²° í™•ì¸
          greeting = await websocket.recv()
          print(f"âœ… {greeting}\n")
          
          # 5ê°œ ì²­í¬ ì „ì†¡ ë° ë ˆì´í„´ì‹œ ì¸¡ì •
          latencies = []
          
          for i in range(5):
              # ëœë¤ ì˜¤ë””ì˜¤ ì²­í¬ ìƒì„± (1ì´ˆ, 16kHz, float32)
              chunk = (np.random.randn(16000) * 0.1).astype(np.float32)
              chunk_bytes = (chunk * 32768).astype(np.int16).tobytes()
              
              # ì „ì†¡ ë° ì‹œê°„ ì¸¡ì •
              start_time = time.time()
              await websocket.send(chunk_bytes)
              
              response = await websocket.recv()
              end_time = time.time()
              
              latency = (end_time - start_time) * 1000  # ms
              latencies.append(latency)
              
              print(f"Chunk {i+1}: {latency:.2f}ms")
              print(f"  Response: {response}\n")
          
          # í†µê³„
          avg_latency = sum(latencies) / len(latencies)
          print("=" * 50)
          print(f"ğŸ“Š Average Latency: {avg_latency:.2f}ms")
          
          if avg_latency > 3000:
              print("âš ï¸ Warning: Average latency exceeds 3 seconds!")
          elif avg_latency > 2000:
              print("âš ï¸ Warning: Average latency exceeds 2 seconds!")
          else:
              print("âœ… Latency target achieved!")
  
  if __name__ == "__main__":
      asyncio.run(main())
```
  
  **ì‹¤í–‰**:
```bash
  # ì„œë²„ ì‹¤í–‰ (í„°ë¯¸ë„ 1)
  # âš ï¸ Whisper í˜¸í™˜ì„±ì„ ìœ„í•´ venv311 ì‚¬ìš© í•„ìš”
  cd server
  venv311\Scripts\activate  # Windows
  # source venv311/bin/activate  # Linux/Mac
  uvicorn main:app --reload
  
  # E2E í…ŒìŠ¤íŠ¸ (í„°ë¯¸ë„ 2)
  cd server
  venv311\Scripts\activate  # Windows
  # source venv311/bin/activate  # Linux/Mac
  python tests/test_e2e_deepgram.py
```

- [ ] **3.2. Whisper vs Deepgram ë ˆì´í„´ì‹œ ë¹„êµ**
```bash
  # Whisper ë²„ì „ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ (T24 ì„œë²„)
  python tests/test_e2e.py
  # ê²°ê³¼: í‰ê·  1.99s (ì›œì—… ì´í›„)
  
  # Deepgram ë²„ì „ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ (T27 ì„œë²„)
  python tests/test_e2e_deepgram.py
  # ëª©í‘œ: í‰ê·  1.0~1.5s
```

### Phase 4: í´ë¼ì´ì–¸íŠ¸ ì§ì ‘ ì—°ë™ ë°©ì‹ (ì„ íƒ ì‚¬í•­, ë³´ì•ˆ ì´ìŠˆ)

âš ï¸ **ì£¼ì˜**: ì´ ë°©ì‹ì€ API í‚¤ê°€ í´ë¼ì´ì–¸íŠ¸ì— ë…¸ì¶œë˜ë¯€ë¡œ **í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ê¶Œì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤**.
MVP/ë°ëª¨ ëª©ì ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ì„¸ìš”.

<details>
<summary>í´ë¼ì´ì–¸íŠ¸ ì§ì ‘ ì—°ë™ ì½”ë“œ (ì°¸ê³ ìš©)</summary>
```typescript
// electron/audio/deepgramClient.ts
import WebSocket from 'ws';
import { EventEmitter } from 'events';

export class DeepgramClient extends EventEmitter {
  private ws: WebSocket | null = null;
  private apiKey: string;
  
  constructor(apiKey: string) {
    super();
    this.apiKey = apiKey;
  }
  
  async connect(): Promise<void> {
    const url = `wss://api.deepgram.com/v1/listen?encoding=linear16&sample_rate=16000&language=ko`;
    
    this.ws = new WebSocket(url, {
      headers: {
        'Authorization': `Token ${this.apiKey}`,
      },
    });
    
    this.ws.on('open', () => {
      console.log('âœ… Deepgram WebSocket connected');
      this.emit('connected');
    });
    
    this.ws.on('message', (data: Buffer) => {
      try {
        const response = JSON.parse(data.toString());
        
        if (response.channel?.alternatives) {
          const transcript = response.channel.alternatives[0].transcript;
          if (transcript && transcript.trim() !== '') {
            this.emit('transcript', transcript);
          }
        }
      } catch (err) {
        console.error('Failed to parse Deepgram response:', err);
      }
    });
    
    this.ws.on('error', (err) => {
      console.error('Deepgram WebSocket error:', err);
      this.emit('error', err);
    });
    
    this.ws.on('close', () => {
      console.log('Deepgram WebSocket closed');
      this.emit('close');
    });
  }
  
  sendAudio(audioBuffer: Buffer): void {
    if (this.ws && this.ws.readyState === WebSocket.OPEN) {
      this.ws.send(audioBuffer);
    }
  }
  
  disconnect(): void {
    if (this.ws) {
      this.ws.close();
      this.ws = null;
    }
  }
}
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```typescript
// electron/audio/audioService.ts (ìˆ˜ì •)
import { DeepgramClient } from './deepgramClient';

export class AudioService {
  private deepgramClient: DeepgramClient;
  
  constructor(private mainWindow: BrowserWindow | null) {
    // âš ï¸ ë³´ì•ˆ ìœ„í—˜: API í‚¤ê°€ í´ë¼ì´ì–¸íŠ¸ì— ë…¸ì¶œë¨
    this.deepgramClient = new DeepgramClient(process.env.DEEPGRAM_API_KEY!);
    
    this.deepgramClient.on('transcript', (text: string) => {
      // FastAPI /analyze-text ì—”ë“œí¬ì¸íŠ¸ë¡œ ì „ì†¡
      this.analyzeText(text);
    });
  }
  
  async startMonitoring(): Promise<void> {
    await this.deepgramClient.connect();
    
    // ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹œì‘
    this.audioIn.on('data', (chunk: Buffer) => {
      const processed = this.processor.process(chunk);
      this.deepgramClient.sendAudio(processed);
    });
  }
  
  private async analyzeText(text: string): Promise<void> {
    // FastAPIë¡œ í…ìŠ¤íŠ¸ë§Œ ì „ì†¡
    const response = await axios.post('http://localhost:8000/analyze-text', {
      text: text
    });
    
    if (response.data.is_harmful) {
      this.handleHarmful(text, response.data.confidence);
    }
  }
}
```

**ë³´ì•ˆ ê°œì„  ë°©ë²•** (ì¶”ê°€ ì‘ì—… í•„ìš”):
1. FastAPIì—ì„œ ì„ì‹œ í† í° ë°œê¸‰ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
2. Electronì—ì„œ í† í° ìš”ì²­ í›„ Deepgram ì—°ê²°
3. í† í° ìˆ˜ëª…: 30ë¶„ (ìë™ ê°±ì‹ )

ì´ ë°©ì‹ì€ 120ì‹œê°„ MVP ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë¯€ë¡œ ì„ íƒ ì‚¬í•­ì…ë‹ˆë‹¤.
</details>

## ğŸ”— ê´€ë ¨ íŒŒì¼

### ìƒì„±í•  íŒŒì¼
- `server/audio/deepgram_service.py` - Deepgram STT ì„œë¹„ìŠ¤
- `server/tests/test_deepgram_service.py` - Deepgram ì„œë¹„ìŠ¤ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
- `server/tests/test_e2e_deepgram.py` - Deepgram E2E í…ŒìŠ¤íŠ¸
- `electron/audio/deepgramClient.ts` - í´ë¼ì´ì–¸íŠ¸ ì§ì ‘ ì—°ë™ (ì„ íƒ ì‚¬í•­)

### ìˆ˜ì •í•  íŒŒì¼
- `server/requirements.txt` - Deepgram SDK ì¶”ê°€
- `server/main.py` - DeepgramSTTService ì‚¬ìš©
- `server/.env` - DEEPGRAM_API_KEY ì¶”ê°€
- `server/audio/pipeline.py` - ì£¼ì„ ì—…ë°ì´íŠ¸ (ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜ì„± ê°•ì¡°)

## ğŸ“Š í…ŒìŠ¤íŠ¸ ê³„íš

| Phase | í…ŒìŠ¤íŠ¸ í•­ëª© | ì„±ê³µ ê¸°ì¤€ | ìš°ì„ ìˆœìœ„ |
|-------|-------------|-----------|----------|
| 1 | Deepgram API ì—°ê²° | ë¬´ìŒ ì˜¤ë””ì˜¤ ì „ì†¡ ì„±ê³µ | High |
| 2 | ì‹¤ì œ ì˜¤ë””ì˜¤ ë³€í™˜ | í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì •í™•íˆ ì¶”ì¶œ | High |
| 3 | Pipeline í†µí•© | WhisperSTTServiceì™€ ë™ì¼í•œ ê²°ê³¼ | High |
| 4 | E2E ë ˆì´í„´ì‹œ | í‰ê·  2ì´ˆ ì´ë‚´ (Whisper ëŒ€ë¹„ 30% ë‹¨ì¶•) | Critical |
| 5 | í´ë¼ì´ì–¸íŠ¸ ì§ì ‘ ì—°ë™ | í…ìŠ¤íŠ¸ë§Œ FastAPIë¡œ ì „ì†¡ (ì„ íƒ ì‚¬í•­) | Low |

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **Python í™˜ê²½ ì„¤ì •**
   - **Whisper í˜¸í™˜ì„± ë¬¸ì œë¡œ ì¸í•´ `server/venv311` (Python 3.11) í™˜ê²½ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.**
   - ì„œë²„ ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸ ì‹œ venv311 í™œì„±í™” í•„ìˆ˜
   - Windows: `venv311\Scripts\activate`
   - Linux/Mac: `source venv311/bin/activate`

2. **API í‚¤ ë³´ì•ˆ**
   - `.env` íŒŒì¼ì— `DEEPGRAM_API_KEY` ì¶”ê°€
   - `.gitignore`ì— `.env` í¬í•¨ í™•ì¸
   - í´ë¼ì´ì–¸íŠ¸ì— API í‚¤ ë…¸ì¶œ ê¸ˆì§€

3. **ë¹„ìš© ê´€ë¦¬**
   - Deepgram ë¬´ë£Œ í¬ë ˆë”§: $200
   - ì¢…ëŸ‰ì œ: ë¶„ë‹¹ $0.0125 (í•œêµ­ì–´ ëª¨ë¸)
   - 1ì‹œê°„ í…ŒìŠ¤íŠ¸ = $0.75
   - ë¬´ë£Œ í¬ë ˆë”§ìœ¼ë¡œ ì•½ 16,000ë¶„ ì‚¬ìš© ê°€ëŠ¥

4. **ì–¸ì–´ ì½”ë“œ**
   - í•œêµ­ì–´: `language="ko"`
   - ë‹¤êµ­ì–´ ì§€ì›: `language="multi"`
   - ëª¨ë¸ ì„ íƒ: `model="general"` ë˜ëŠ” `model="nova-2"` (ìµœì‹ )

5. **ì—ëŸ¬ ì²˜ë¦¬**
   - API í‚¤ ì—†ìŒ â†’ `ValueError` ë°œìƒ
   - ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ â†’ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
   - ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜ â†’ ë¡œê·¸ ì¶œë ¥ í›„ ë¬´ì‹œ

6. **ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜ì„±**
   - `WhisperSTTService`ì™€ ë™ì¼í•œ `transcribe(audio_chunk)` ë©”ì„œë“œ ì œê³µ
   - `AudioProcessingPipeline`ì€ ìˆ˜ì • ì—†ì´ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- [Deepgram Python SDK](https://developers.deepgram.com/docs/python-sdk)
- [Deepgram Streaming API](https://developers.deepgram.com/docs/streaming)
- [Deepgram ì–¸ì–´ ì§€ì›](https://developers.deepgram.com/docs/languages)
- [Deepgram ìš”ê¸ˆì œ](https://deepgram.com/pricing)

## ğŸ—’ï¸ ì—…ë°ì´íŠ¸ ë¡œê·¸

- 2024-11-13: T27 ë¬¸ì„œ ì‘ì„±, Deepgram í†µí•© ê³„íš ìˆ˜ë¦½

## ğŸ”„ ë‹¤ìŒ ì‘ì—…

T27 ì™„ë£Œ í›„:
- â³ **Phase 4: í´ë¼ì´ì–¸íŠ¸ ì§ì ‘ ì—°ë™** (ì„ íƒ ì‚¬í•­)
  - ë³´ì•ˆ í† í° ë°œê¸‰ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
  - Electronì—ì„œ Deepgram ì§ì ‘ ì—°ê²°
- â³ **T16: ì„œë²„ ì•Œë¦¼ ìˆ˜ì‹  ë° ë¸”ë¼ì¸ë“œ í‘œì‹œ** í†µí•©
  - OCR(í…ìŠ¤íŠ¸) + STT(ìŒì„±) ìœ í•´ì„± ê°ì§€ í†µí•©
  - í†µí•© ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬ì¶•

---

**ì™„ë£Œ ê¸°ì¤€**:
- [x] Deepgram SDK v5 ì„¤ì¹˜ ë° API í‚¤ ì„¤ì •
- [x] DeepgramSTTService SDK v5 ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ ì™„ë£Œ
- [x] ì¡°ìš©í•œ ì˜¤ë””ì˜¤ ì¡°ê¸° ì¢…ë£Œ ë¡œì§ ì¶”ê°€
- [x] ë ˆì´í„´ì‹œ ì¸¡ì • ë° ë¡œê¹… ì¶”ê°€
- [x] AudioProcessingPipeline í†µí•© ì™„ë£Œ
- [ ] E2E í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° í‰ê·  ë ˆì´í„´ì‹œ 2ì´ˆ ì´ë‚´ ë‹¬ì„±
- [ ] Whisper vs Deepgram ë ˆì´í„´ì‹œ ë¹„êµ ë³´ê³ ì„œ ì‘ì„±