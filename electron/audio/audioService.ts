/**
 * Phase 3: ì˜¤ë””ì˜¤ ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ (ë©”ì¸ í”„ë¡œì„¸ìŠ¤)
 * 
 * ì˜¤ë””ì˜¤ ìº¡ì²˜, ì²˜ë¦¬, WebSocket í†µì‹ ì„ í†µí•© ê´€ë¦¬í•©ë‹ˆë‹¤.
 */

import { BrowserWindow } from 'electron';
import naudiodon from 'naudiodon2';
import { AudioProcessor } from './audioProcessor';
import { AudioStreamClient, AudioStreamResponse } from './audioStreamClient';
import { IPC_CHANNELS } from '../ipc/channels';
import { AppVolumeController } from './appVolumeController';

export class AudioService {
  private isMonitoring = false;
  private audioIn: any = null;
  private processor: AudioProcessor;
  private streamClient: AudioStreamClient;
  private volumeLevel = 1; // 0~10, ê¸°ë³¸ê°’ 1 (1ë‹¨ê³„ ë³¼ë¥¨)
  private beepEnabled = false;
  private volumeController: AppVolumeController;
  private targetAppName: string | null = null; // ëª¨ë‹ˆí„°ë§í•  ì•± ì´ë¦„ (nullì´ë©´ ëª¨ë“  ì•±)
  private windows: Set<BrowserWindow> = new Set(); // ì—¬ëŸ¬ ìœˆë„ìš° ì§€ì›
  
  constructor(initialWindow: BrowserWindow | null) {
    // AudioProcessorëŠ” startMonitoringì—ì„œ ì‹¤ì œ ë””ë°”ì´ìŠ¤ ìƒ˜í”Œ ë ˆì´íŠ¸ë¡œ ì´ˆê¸°í™”ë¨
    // ì„ì‹œë¡œ 48000ìœ¼ë¡œ ì´ˆê¸°í™” (ì‹¤ì œë¡œëŠ” startMonitoringì—ì„œ ì¬ì„¤ì •ë¨)
    this.processor = new AudioProcessor(48000, 16000);
    this.streamClient = new AudioStreamClient('ws://127.0.0.1:8000/ws/audio');
    this.volumeController = new AppVolumeController();
    
    if (initialWindow) {
      this.windows.add(initialWindow);
    }
    
    // ì„œë²„ ì‘ë‹µ ë¦¬ìŠ¤ë„ˆ
    this.streamClient.on('response', (response: AudioStreamResponse) => {
      void this.handleServerResponse(response);
    });
    
    this.streamClient.on('error', (err) => {
      console.error('[AudioService] WebSocket error:', err);
    });
    
    this.streamClient.on('close', () => {
      console.log('[AudioService] WebSocket connection closed');
      if (this.isMonitoring) {
        // ì¬ì—°ê²° ì‹œë„
        console.log('[AudioService] Attempting to reconnect...');
        setTimeout(() => {
          this.streamClient.connect().catch(console.error);
        }, 1000);
      }
    });
  }
  
  /**
   * ìœˆë„ìš° ì¶”ê°€ (ì—¬ëŸ¬ ìœˆë„ìš°ì—ì„œ ì˜¤ë””ì˜¤ ìƒíƒœ ìˆ˜ì‹  ê°€ëŠ¥)
   */
  addWindow(window: BrowserWindow): void {
    this.windows.add(window);
    console.log(`[AudioService] Window added (total: ${this.windows.size})`);
    
    // í˜„ì¬ ìƒíƒœë¥¼ ìƒˆ ìœˆë„ìš°ì— ì „ì†¡
    this.broadcastStatus();
  }
  
  /**
   * ìœˆë„ìš° ì œê±°
   */
  removeWindow(window: BrowserWindow): void {
    this.windows.delete(window);
    console.log(`[AudioService] Window removed (total: ${this.windows.size})`);
  }
  
  async startMonitoring(): Promise<void> {
    if (this.isMonitoring) {
      console.log('[AudioService] Audio monitoring already started');
      return;
    }
    
    try {
      // WebSocket ì—°ê²°
      await this.streamClient.connect();
      
      // ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹œì‘
      const devices = naudiodon.getDevices();
      console.log(`[AudioService] Found ${devices.length} audio devices:`);
      devices.forEach((d, idx) => {
        console.log(`  [${idx}] ${d.name} - Input: ${d.maxInputChannels}, Output: ${d.maxOutputChannels}, SampleRate: ${d.defaultSampleRate}`);
        // ë””ë°”ì´ìŠ¤ ìƒì„¸ ì •ë³´ ì¶œë ¥ (ìˆëŠ” ê²½ìš°)
        if ((d as any).hostAPI) {
          console.log(`       HostAPI: ${(d as any).hostAPI}`);
        }
      });
      
      // WASAPI Loopback ë””ë°”ì´ìŠ¤ ì°¾ê¸°
      // Windows naudiodon2ì—ì„œëŠ” ì¶œë ¥ ë””ë°”ì´ìŠ¤ë¥¼ ì…ë ¥ ë””ë°”ì´ìŠ¤ë¡œ ì‚¬ìš©í•´ì•¼ í•¨
      // naudiodon2ëŠ” ì¶œë ¥ ë””ë°”ì´ìŠ¤ì— ëŒ€í•´ maxInputChannelsë¥¼ ì„¤ì •í•˜ì—¬ Loopbackì„ ì§€ì›
      
      // ë””ë°”ì´ìŠ¤ ì„ íƒ ì „ëµ:
      // 1ìˆœìœ„: ìŠ¤í…Œë ˆì˜¤ ë¯¹ìŠ¤ (ëª…ì‹œì  - ê°€ì¥ ì•ˆì •ì )
      // 2ìˆœìœ„: 48000Hz ìŠ¤í…Œë ˆì˜¤ ë¯¹ìŠ¤ (ë” ë‚˜ì€ ìƒ˜í”Œ ë ˆì´íŠ¸)
      // 3ìˆœìœ„: WASAPI Loopback ë””ë°”ì´ìŠ¤
      // 4ìˆœìœ„: ì¶œë ¥ ë””ë°”ì´ìŠ¤
      
      // 1ìˆœìœ„: ìŠ¤í…Œë ˆì˜¤ ë¯¹ìŠ¤ (44100Hz)
      let loopbackDevice = devices.find(d => {
        const nameLower = d.name.toLowerCase();
        const isStereoMix = nameLower.includes('stereo mix') || 
                           nameLower.includes('ìŠ¤í…Œë ˆì˜¤ ë¯¹ìŠ¤') ||
                           nameLower.includes('stereo ë¯¹ìŠ¤');
        return isStereoMix && d.defaultSampleRate === 44100;
      });
      
      // 2ìˆœìœ„: ìŠ¤í…Œë ˆì˜¤ ë¯¹ìŠ¤ (48000Hz) - ë” ë‚˜ì€ ìƒ˜í”Œ ë ˆì´íŠ¸
      if (!loopbackDevice) {
        loopbackDevice = devices.find(d => {
          const nameLower = d.name.toLowerCase();
          const isStereoMix = nameLower.includes('stereo mix') || 
                             nameLower.includes('ìŠ¤í…Œë ˆì˜¤ ë¯¹ìŠ¤') ||
                             nameLower.includes('stereo ë¯¹ìŠ¤');
          return isStereoMix && d.defaultSampleRate === 48000;
        });
      }
      
      // 3ìˆœìœ„: ëª¨ë“  ìŠ¤í…Œë ˆì˜¤ ë¯¹ìŠ¤
      if (!loopbackDevice) {
        loopbackDevice = devices.find(d => {
          const nameLower = d.name.toLowerCase();
          return nameLower.includes('stereo mix') || 
                 nameLower.includes('ìŠ¤í…Œë ˆì˜¤ ë¯¹ìŠ¤') ||
                 nameLower.includes('stereo ë¯¹ìŠ¤');
        });
      }
      
      if (loopbackDevice) {
        console.log(`[AudioService] ğŸ¯ Found Stereo Mix device: ${loopbackDevice.name} (Sample rate: ${loopbackDevice.defaultSampleRate} Hz)`);
      }
      
      if (!loopbackDevice) {
        // 4ìˆœìœ„: WASAPI Loopback ë””ë°”ì´ìŠ¤ (ì¶œë ¥ ë””ë°”ì´ìŠ¤ ì¤‘ ì…ë ¥ ì±„ë„ì´ ìˆëŠ” ê²ƒ)
        // Windows 10/11ì—ì„œëŠ” ì¶œë ¥ ë””ë°”ì´ìŠ¤ê°€ Loopbackìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥ (naudiodon2 ì§€ì›)
        // ì¶œë ¥ ì±„ë„ì´ ìˆê³ , ì…ë ¥ ì±„ë„ë„ ìˆìœ¼ë©´ì„œ ë§ˆì´í¬ê°€ ì•„ë‹Œ ê²ƒ
        const candidates = devices.filter(d => {
          const hasOutput = d.maxOutputChannels > 0;
          const hasInput = d.maxInputChannels > 0;
          const nameLower = d.name.toLowerCase();
          const isNotMic = !nameLower.includes('microphone') && 
                          !nameLower.includes('ë§ˆì´í¬') &&
                          !nameLower.includes('mic') &&
                          !nameLower.includes('headset') &&
                          !nameLower.includes('headphone') &&
                          !nameLower.includes('í—¤ë“œì…‹') &&
                          !nameLower.includes('í—¤ë“œí°');
          
          return hasOutput && hasInput && isNotMic;
        });
        
        if (candidates.length > 0) {
          // ì¶œë ¥ ì±„ë„ì´ ê°€ì¥ ë§ì€ ë””ë°”ì´ìŠ¤ ì„ íƒ (ì¼ë°˜ì ìœ¼ë¡œ ê¸°ë³¸ ì¶œë ¥ ë””ë°”ì´ìŠ¤)
          loopbackDevice = candidates.sort((a, b) => b.maxOutputChannels - a.maxOutputChannels)[0];
          console.log(`[AudioService] ğŸ¯ Found WASAPI Loopback device: ${loopbackDevice.name} (Output: ${loopbackDevice.maxOutputChannels}, Input: ${loopbackDevice.maxInputChannels})`);
          console.log(`[AudioService] Other candidates: ${candidates.slice(1).map(d => d.name).join(', ')}`);
        }
      }
      
      if (!loopbackDevice) {
        // 5ìˆœìœ„: ì¶œë ¥ ì±„ë„ì´ ìˆëŠ” ë””ë°”ì´ìŠ¤ (ìŠ¤í”¼ì»¤ ë“± - ë§ˆì§€ë§‰ ìˆ˜ë‹¨)
        // naudiodon2ê°€ Loopbackì„ ì§€ì›í•˜ëŠ” ê²½ìš°ì—ë§Œ ì‘ë™
        const outputDevices = devices.filter(d => {
          const hasOutput = d.maxOutputChannels > 0;
          const nameLower = d.name.toLowerCase();
          const isNotMic = !nameLower.includes('microphone') && 
                          !nameLower.includes('ë§ˆì´í¬') &&
                          !nameLower.includes('mic');
          
          return hasOutput && isNotMic;
        });
        
        if (outputDevices.length > 0) {
          // ì¶œë ¥ ì±„ë„ì´ ê°€ì¥ ë§ì€ ë””ë°”ì´ìŠ¤ ì„ íƒ
          loopbackDevice = outputDevices.sort((a, b) => b.maxOutputChannels - a.maxOutputChannels)[0];
          console.log(`[AudioService] âš ï¸ Using output device as loopback (may not work): ${loopbackDevice.name} (Output: ${loopbackDevice.maxOutputChannels}, Input: ${loopbackDevice.maxInputChannels})`);
          console.warn(`[AudioService] âš ï¸ This device has no input channels - loopback may fail!`);
        }
      }
      
      if (!loopbackDevice) {
        console.error('[AudioService] âŒ No loopback device found!');
        console.error('[AudioService] Available devices:');
        devices.forEach((d, idx) => {
          console.error(`  [${idx}] ${d.name} - Input: ${d.maxInputChannels}, Output: ${d.maxOutputChannels}`);
        });
        console.error('[AudioService] ğŸ’¡ Please check:');
        console.error('[AudioService]   1. Windows Sound Settings > Recording > Enable "Stereo Mix"');
        console.error('[AudioService]   2. Or use a WASAPI-compatible audio device');
        throw new Error('No loopback device found. Please enable "Stereo Mix" in Windows audio settings or check audio device configuration.');
      }
      
      console.log(`[AudioService] âœ… Using audio device: ${loopbackDevice.name} (ID: ${loopbackDevice.id})`);
      console.log(`[AudioService] Device info: Input channels=${loopbackDevice.maxInputChannels}, Output channels=${loopbackDevice.maxOutputChannels}, Sample rate=${loopbackDevice.defaultSampleRate}`);
      
      // ë””ë°”ì´ìŠ¤ê°€ ì‹¤ì œë¡œ ì…ë ¥ì„ ì§€ì›í•˜ëŠ”ì§€ í™•ì¸
      if (loopbackDevice.maxInputChannels === 0) {
        console.warn('[AudioService] âš ï¸ Selected device has no input channels. This may not work for loopback capture.');
        console.warn('[AudioService] âš ï¸ Trying anyway, but audio capture may fail.');
      }
      
      // ìŠ¤í…Œë ˆì˜¤ ë¯¹ìŠ¤ ì‚¬ìš© ì‹œ ì¤‘ìš” ì•ˆë‚´ì‚¬í•­
      if (loopbackDevice.name.includes('ìŠ¤í…Œë ˆì˜¤ ë¯¹ìŠ¤') || loopbackDevice.name.toLowerCase().includes('stereo mix')) {
        console.log(`[AudioService] ğŸ“¢ IMPORTANT: Stereo Mix device detected (${loopbackDevice.defaultSampleRate} Hz).`);
        console.log(`[AudioService] ğŸ“¢ â„¹ï¸  Stereo Mix captures audio from your DEFAULT playback device (speakers/headphones).`);
        console.log(`[AudioService] ğŸ“¢ â„¹ï¸  You do NOT need to remove headphones - it will capture audio playing through them.`);
        console.log(`[AudioService] ğŸ“¢ âš ï¸  CRITICAL CHECKLIST:`);
        console.log(`[AudioService] ğŸ“¢   1. Is audio ACTUALLY playing? (YouTube, Discord, etc.) - Audio must be playing for capture to work!`);
        console.log(`[AudioService] ğŸ“¢   2. Check Windows Sound Settings > Recording tab - Stereo Mix audio bars MUST move when audio plays`);
        console.log(`[AudioService] ğŸ“¢   3. If audio bars don't move: Stereo Mix is not capturing audio - check Windows audio settings`);
        console.log(`[AudioService] ğŸ“¢   4. Check default playback device (System > Sound > Output) - must match your speakers/headphones`);
        console.log(`[AudioService] ğŸ“¢   5. Stereo Mix volume: 100% in Properties > Levels tab`);
        console.log(`[AudioService] ğŸ“¢   6. System playback volume: Should be > 0%`);
        console.log(`[AudioService] ğŸ“¢   7. Close other apps using Stereo Mix (OBS, Discord, etc.)`);
        console.log(`[AudioService] ğŸ“¢   8. If still not working: Try restarting Windows Audio Service (services.msc > Windows Audio)`);
      }
      
      // ë””ë°”ì´ìŠ¤ê°€ ì§€ì›í•˜ëŠ” ì…ë ¥ ì±„ë„ ìˆ˜ í™•ì¸
      // WASAPI Loopbackì˜ ê²½ìš° ì¶œë ¥ ë””ë°”ì´ìŠ¤ë¥¼ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ë¯€ë¡œ,
      // maxInputChannelsê°€ 0ì¼ ìˆ˜ ìˆì§€ë§Œ ì‹¤ì œë¡œëŠ” ì‘ë™í•  ìˆ˜ ìˆìŒ
      const inputChannels = loopbackDevice.maxInputChannels > 0 
        ? Math.min(2, loopbackDevice.maxInputChannels) 
        : 2; // ì…ë ¥ ì±„ë„ì´ ì—†ì–´ë„ ì‹œë„ (WASAPI Loopbackì€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
      const sampleRate = loopbackDevice.defaultSampleRate || 48000;
      
      // AudioProcessorë¥¼ ì‹¤ì œ ë””ë°”ì´ìŠ¤ ìƒ˜í”Œ ë ˆì´íŠ¸ë¡œ ì¬ì´ˆê¸°í™”
      // ì¤‘ìš”: ë””ë°”ì´ìŠ¤ ìƒ˜í”Œ ë ˆì´íŠ¸ì™€ AudioProcessor ì…ë ¥ ìƒ˜í”Œ ë ˆì´íŠ¸ê°€ ì¼ì¹˜í•´ì•¼ í•¨
      this.processor = new AudioProcessor(sampleRate, 16000);
      console.log(`[AudioService] AudioProcessor initialized: ${sampleRate} Hz â†’ 16000 Hz`);
      
      console.log(`[AudioService] Creating audio stream:`);
      console.log(`[AudioService]   - Device: ${loopbackDevice.name} (ID: ${loopbackDevice.id})`);
      console.log(`[AudioService]   - Channels: ${inputChannels} (device supports: ${loopbackDevice.maxInputChannels} input, ${loopbackDevice.maxOutputChannels} output)`);
      console.log(`[AudioService]   - Sample rate: ${sampleRate} Hz`);
      console.log(`[AudioService]   - Format: 16-bit PCM`);
      
      try {
        this.audioIn = new naudiodon.AudioIO({
          inOptions: {
            channelCount: inputChannels,
            sampleFormat: 16,
            sampleRate: sampleRate,
            deviceId: loopbackDevice.id,
            closeOnError: true
          }
        });
        console.log(`[AudioService] âœ… Audio stream created successfully`);
      } catch (err: any) {
        console.error(`[AudioService] âŒ Failed to create audio stream:`, err);
        throw new Error(`Failed to create audio stream for device ${loopbackDevice.name}: ${err.message}`);
      }
      
      // ì˜¤ë””ì˜¤ ì²­í¬ í†µê³„ ì¶”ì  (ì²« ë²ˆì§¸ ì²­í¬ë§Œ ìƒì„¸ ë¡œê¹…)
      let chunkCount = 0;
      let lastLogTime = Date.now();
      
      this.audioIn.on('data', (chunk: Buffer) => {
        chunkCount++;
        const now = Date.now();
        
        // ì˜¤ë””ì˜¤ ì²­í¬ í†µê³„ ê³„ì‚°
        // ìŠ¤í…Œë ˆì˜¤ 16-bit: chunk.length = samples * 2 * 2 (2 channels, 2 bytes per sample)
        const samples = chunk.length / 4; // ìŠ¤í…Œë ˆì˜¤ = 4 bytes per sample pair
        let sum = 0;
        let max = 0;
        let nonZeroSamples = 0;
        
        for (let i = 0; i < samples; i++) {
          // Left channel
          const left = Math.abs(chunk.readInt16LE(i * 4));
          // Right channel
          const right = Math.abs(chunk.readInt16LE(i * 4 + 2));
          // í‰ê· 
          const sample = Math.floor((left + right) / 2);
          
          sum += sample;
          max = Math.max(max, sample);
          if (sample > 0) {
            nonZeroSamples++;
          }
        }
        
        const mean = sum / samples;
        const meanAbs = mean / 32768.0; // ì •ê·œí™” (0.0 ~ 1.0)
        const maxAbs = max / 32768.0;
        const nonZeroRatio = nonZeroSamples / samples;
        
        // ì²« ë²ˆì§¸ ì²­í¬ ë˜ëŠ” ì£¼ê¸°ì ìœ¼ë¡œ ìƒì„¸ ë¡œê¹…
        if (chunkCount === 1 || (now - lastLogTime) > 5000) {
          console.log(`[AudioService] Audio chunk #${chunkCount}: size=${chunk.length} bytes, samples=${samples}, mean_abs=${meanAbs.toFixed(6)}, max_abs=${maxAbs.toFixed(6)}, non_zero=${(nonZeroRatio * 100).toFixed(1)}%`);
          
          // ì˜¤ë””ì˜¤ ì‹ í˜¸ ê°•ë„ í‰ê°€
          // ì°¸ê³ : ì •ìƒ ì˜¤ë””ì˜¤ ì‹ í˜¸ëŠ” ë³´í†µ mean_abs > 0.01 ì´ìƒ (ìŒì„±: 0.01~0.1, ìŒì•…: 0.1~0.5)
          // í˜„ì¬ ì‹ í˜¸: mean_abs=0.000054 ~ 0.000065 (ì •ìƒ ëŒ€ë¹„ 200ë°° ì´ìƒ ì•½í•¨)
          if (meanAbs < 0.0001) {
            // ë§¤ìš° ì¡°ìš©í•¨ (ê±°ì˜ ë¬´ìŒ) - STT ë¶ˆê°€ëŠ¥
            console.warn(`[AudioService] âš ï¸ Audio signal is extremely quiet (mean_abs=${meanAbs.toFixed(6)}) - STT will likely fail`);
            console.warn(`[AudioService] âš ï¸ Current signal is ~200x weaker than normal speech (need > 0.01)`);
            if (chunkCount === 1 || chunkCount % 50 === 0) {
              console.warn(`[AudioService] âš ï¸ ========================================`);
              console.warn(`[AudioService] âš ï¸ CRITICAL: Stereo Mix volume is too low!`);
              console.warn(`[AudioService] âš ï¸ ========================================`);
              console.warn(`[AudioService] âš ï¸ Action required:`);
              console.warn(`[AudioService] âš ï¸   1. Windows Settings > Sound > Sound Control Panel`);
              console.warn(`[AudioService] âš ï¸   2. Recording tab > Find "Stereo Mix"`);
              console.warn(`[AudioService] âš ï¸   3. Right-click > Properties > Levels tab`);
              console.warn(`[AudioService] âš ï¸   4. Set volume to 100% (NOT 50%, NOT 80% - use 100%!)`);
              console.warn(`[AudioService] âš ï¸   5. Make sure it's NOT muted`);
              console.warn(`[AudioService] âš ï¸   6. Play audio (YouTube, Discord) - check if audio bars move`);
              console.warn(`[AudioService] âš ï¸   7. Restart app after changing volume`);
              console.warn(`[AudioService] âš ï¸ ========================================`);
            }
          } else if (meanAbs < 0.001) {
            // ì¡°ìš©í•¨ (ì‹ í˜¸ëŠ” ìˆì§€ë§Œ ì•½í•¨) - STT ê°€ëŠ¥í•˜ì§€ë§Œ í’ˆì§ˆ ë‚®ìŒ
            console.warn(`[AudioService] âš ï¸ Audio signal is very quiet (mean_abs=${meanAbs.toFixed(6)}) - STT may fail`);
            console.warn(`[AudioService] âš ï¸ Current signal is ~10-100x weaker than normal speech (need > 0.01)`);
            console.warn(`[AudioService] âš ï¸ Consider increasing Stereo Mix recording volume to 100%`);
          } else if (meanAbs < 0.01) {
            // ì•½í•œ ì‹ í˜¸ (STT ê°€ëŠ¥í•˜ì§€ë§Œ í’ˆì§ˆ ë‚®ì„ ìˆ˜ ìˆìŒ)
            console.log(`[AudioService] âš ï¸ Audio signal is weak (mean_abs=${meanAbs.toFixed(4)}) - STT may work but quality may be low`);
            console.log(`[AudioService] ğŸ’¡ Consider increasing Stereo Mix recording volume for better results`);
          } else {
            // ì •ìƒ ì‹ í˜¸ (STT ì •ìƒ ì‘ë™ ê°€ëŠ¥)
            console.log(`[AudioService] âœ… Audio signal detected: mean_abs=${meanAbs.toFixed(4)}, max_abs=${maxAbs.toFixed(4)} - STT should work`);
          }
          
          lastLogTime = now;
        }
        
        const processed = this.processor.process(chunk);
        
        // ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ í¬ê¸° í™•ì¸
        if (processed.length === 0) {
          console.error('[AudioService] âŒ Processed audio is empty!');
          return;
        }
        
        // ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ì‹ í˜¸ ê°•ë„ í™•ì¸ (ë””ë²„ê¹…)
        if (chunkCount === 1 || chunkCount % 50 === 0) {
          const processedSamples = processed.length / 2; // 16-bit = 2 bytes
          let processedSum = 0;
          let processedMax = 0;
          for (let i = 0; i < processedSamples; i++) {
            const sample = Math.abs(processed.readInt16LE(i * 2));
            processedSum += sample;
            processedMax = Math.max(processedMax, sample);
          }
          const processedMean = processedSum / processedSamples;
          const processedMeanAbs = processedMean / 32768.0;
          const processedMaxAbs = processedMax / 32768.0;
          
          console.log(`[AudioService] Processed audio: size=${processed.length} bytes, samples=${processedSamples}, mean_abs=${processedMeanAbs.toFixed(6)}, max_abs=${processedMaxAbs.toFixed(6)}`);
          
          if (processedMeanAbs < 0.001) {
            console.warn(`[AudioService] âš ï¸ Processed audio signal is very weak - may cause STT failure on server`);
          }
        }
        
        this.streamClient.sendAudioChunk(processed);
      });
      
      this.audioIn.on('error', (err: Error) => {
        console.error('[AudioService] Audio capture error:', err);
        this.stopMonitoring();
      });
      
      this.audioIn.start();
      this.isMonitoring = true;
      console.log('[AudioService] âœ… Audio monitoring started');
      
      // ë Œë”ëŸ¬ì— ìƒíƒœ ì—…ë°ì´íŠ¸ ì „ì†¡
      this.broadcastStatus();
    } catch (err) {
      console.error('[AudioService] Failed to start audio monitoring:', err);
      throw err;
    }
  }
  
  stopMonitoring(): void {
    if (!this.isMonitoring) {
      return;
    }
    
    // ì˜¤ë””ì˜¤ ìº¡ì²˜ ì¤‘ì§€
    if (this.audioIn) {
      try {
        this.audioIn.quit();
      } catch (err) {
        console.error('[AudioService] Error stopping audio capture:', err);
      }
      this.audioIn = null;
    }
    
    // WebSocket ì—°ê²° ì •ìƒ ì¢…ë£Œ
    try {
      this.streamClient.disconnect();
    } catch (err) {
      console.error('[AudioService] Error disconnecting WebSocket:', err);
    }
    
    this.isMonitoring = false;
    console.log('[AudioService] âœ… Audio monitoring stopped');
    
    void this.volumeController.restoreVolume();
    this.broadcastStatus();
  }
  
  /**
   * ëª¨ë‹ˆí„°ë§í•  ì•± ì„¤ì • (nullì´ë©´ ëª¨ë“  ì•±)
   */
  setTargetApp(appName: string | null): void {
    this.targetAppName = appName;
    console.log(`[AudioService] Target app set to: ${appName || 'all apps'}`);
  }
  
  /**
   * í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì˜¤ë””ì˜¤ ì„¸ì…˜ ì¡°íšŒ
   */
  getAudioSessions() {
    return this.volumeController.getAudioSessions();
  }
  
  private async handleServerResponse(response: AudioStreamResponse): Promise<void> {
    console.log('[AudioService] Server response:', response);

    const isHarmful = response.is_harmful === true || response.is_harmful === 1;
    if (!isHarmful) {
      return;
    }

    console.log(`[AudioService] âš ï¸ HARMFUL AUDIO DETECTED: ${response.text}`);

    // ë“±ë¡ëœ ëª¨ë“  ìœˆë„ìš°ì— ìœ í•´ ê°ì§€ ì•Œë¦¼ ì „ì†¡
    const harmfulData = {
      text: response.text,
      confidence: response.confidence || 0,
      timestamp: response.timestamp || Date.now()
    };
    
    this.windows.forEach((window) => {
      if (!window.isDestroyed()) {
        try {
          window.webContents.send(IPC_CHANNELS.AUDIO_HARMFUL_DETECTED, harmfulData);
          console.log(`[AudioService] Harmful detection sent to window ${window.id}`);
        } catch (err) {
          console.error(`[AudioService] Failed to send harmful detection to window ${window.id}:`, err);
        }
      }
    });

    if (this.beepEnabled) {
      this.playBeep();
      return;
    }

    await this.adjustVolume(this.volumeLevel);
  }
  
  private async adjustVolume(level: number): Promise<void> {
    try {
      // ìœ í•´ í‘œí˜„ ê°ì§€ ì‹œ í•­ìƒ ëª¨ë“  ì•± ìŒì†Œê±° (3ì´ˆ í›„ ìë™ ë³µì›)
      console.log(`[AudioService] ğŸ”‡ Muting all apps for 3 seconds due to harmful content`);
      await this.volumeController.muteAllApps(3000); // 3ì´ˆ í›„ ìë™ ë³µì›
    } catch (error) {
      console.error('[AudioService] Failed to mute apps:', error);
    }
  }
  
  private playBeep(): void {
    // TODO: ë¹„í”„ìŒ ì¬ìƒ (Phase 5ì—ì„œ êµ¬í˜„)
    console.log('[AudioService] ğŸ”” Playing beep sound');
  }
  
  setVolumeLevel(level: number): void {
    this.volumeLevel = Math.max(0, Math.min(10, level));
    console.log(`[AudioService] Volume level set to: ${this.volumeLevel}`);
    this.broadcastStatus();
  }
  
  setBeepEnabled(enabled: boolean): void {
    this.beepEnabled = enabled;
    console.log(`[AudioService] Beep enabled: ${this.beepEnabled}`);
    this.broadcastStatus();
  }
  
  getStatus() {
    return {
      isMonitoring: this.isMonitoring,
      volumeLevel: this.volumeLevel,
      beepEnabled: this.beepEnabled,
      targetAppName: this.targetAppName,
      audioSessions: this.getAudioSessions()
    };
  }
  
  private broadcastStatus(): void {
    const status = this.getStatus();
    
    // ë“±ë¡ëœ ëª¨ë“  ìœˆë„ìš°ì— ìƒíƒœ ì „ì†¡
    this.windows.forEach((window) => {
      if (!window.isDestroyed()) {
        try {
          window.webContents.send(IPC_CHANNELS.AUDIO_STATUS, status);
        } catch (err) {
          console.error(`[AudioService] Failed to broadcast status to window ${window.id}:`, err);
        }
      }
    });
  }
}

